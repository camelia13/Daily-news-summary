{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import string\n",
    "import textblob as tb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26567\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>comment</th>\n",
       "      <th>like</th>\n",
       "      <th>dislike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"연대 법대출신 토익925점 kt취업vs건대 충주캠 무스펙 귀걸이낀 증명사진 이력서...</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"전직 공안 검사 출신 이자나...없는 일도 만들고 없던 말도 만들고...그렇게 일...</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"교활이!  이새.키는  503호뇬 밑에 있을때는 다들 벙어리인줄 알았어.....헐...</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"이렇게 입이 가벼운 작자가 어찌 대권을 노린다는건지... 한심하지 짝이 없는 개누리당\"</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\"연세대나온 아들이 KT간게 뭐대수라고 지잡나온 귀걸이 아빠나 조사해봐라 정권의 개들아\"</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  num                                            comment  like  dislike\n",
       "0   0  \"연대 법대출신 토익925점 kt취업vs건대 충주캠 무스펙 귀걸이낀 증명사진 이력서...    19        1\n",
       "1   1  \"전직 공안 검사 출신 이자나...없는 일도 만들고 없던 말도 만들고...그렇게 일...    17        0\n",
       "2   2  \"교활이!  이새.키는  503호뇬 밑에 있을때는 다들 벙어리인줄 알았어.....헐...    23        7\n",
       "3   3  \"이렇게 입이 가벼운 작자가 어찌 대권을 노린다는건지... 한심하지 짝이 없는 개누리당\"    15        1\n",
       "4   4  \"연세대나온 아들이 KT간게 뭐대수라고 지잡나온 귀걸이 아빠나 조사해봐라 정권의 개들아\"    21        8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = ['num', 'comment', 'like', 'dislike']\n",
    "df = pd.read_csv('naver/0701.csv', encoding='utf-8', header=None)\n",
    "\n",
    "df.columns = colnames\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 공감비율 계산\n",
    "\n",
    "# def favor_cmt(l, d):\n",
    "#     return np.log(l+.5)/(np.log(l+d+1)+1)\n",
    "\n",
    "# df['empathize'] = df.apply(lambda x: favor_cmt(x['like'], x['dislike']), axis=1)\n",
    "\n",
    "# dat = df[(df['empathize'] >= 0.70) & (df['month']==7)] # 공감도 0.8 이상의 댓글만 가져옴\n",
    "# len(dat) # 가져온 후 댓글의 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments with zero like : 9068\n",
      "comments with likes < dislikes : 4092\n",
      "number of comments after removal : 13529\n"
     ]
    }
   ],
   "source": [
    "# 공감 = 0, 공감 < 비공감 댓글의 수\n",
    "\n",
    "print('comments with zero like : %d' %len(df[df['like']==0]))\n",
    "print('comments with likes < dislikes : %d' %len(df[(df['dislike']-df['like'])>0]))\n",
    "\n",
    "# 공감 = 0, 공감 < 비공감 댓글 제거\n",
    "\n",
    "df = df[df['like']!=0]\n",
    "df = df[(df['like']-df['dislike'])>0]\n",
    "print('number of comments after removal : %d' %len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "comments.extend(list(df.comment.values)) # 댓글만 리스트로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data celaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12702\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cmt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>연대 법대출신 토익 점 취업 건대 충주캠 무스펙 귀걸이낀 증명사진 이력서 공기업 취...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>전직 공안 검사 출신 이자나 없는 일도 만들고 없던 말도 만들고 그렇게 일반인 빵갱...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>교활이 이새 키는 호뇬 밑에 있을때는 다들 벙어리인줄 알았어 헐 근데 지금보니 완전...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이렇게 입이 가벼운 작자가 어찌 대권을 노린다는건지 한심하지 짝이 없는 개누리당</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>연세대나온 아들이 간게 뭐대수라고 지잡나온 귀걸이 아빠나 조사해봐라 정권의 개들아</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 cmt\n",
       "0  연대 법대출신 토익 점 취업 건대 충주캠 무스펙 귀걸이낀 증명사진 이력서 공기업 취...\n",
       "1  전직 공안 검사 출신 이자나 없는 일도 만들고 없던 말도 만들고 그렇게 일반인 빵갱...\n",
       "2  교활이 이새 키는 호뇬 밑에 있을때는 다들 벙어리인줄 알았어 헐 근데 지금보니 완전...\n",
       "3       이렇게 입이 가벼운 작자가 어찌 대권을 노린다는건지 한심하지 짝이 없는 개누리당\n",
       "4      연세대나온 아들이 간게 뭐대수라고 지잡나온 귀걸이 아빠나 조사해봐라 정권의 개들아"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ]', ' ', text) # 한글이 아니면 공백으로 치환\n",
    "#     cleaned_text = re.sub('[0-9]', ' ', text)\n",
    "#     cleaned_text = re.sub('[\\{\\}\\[\\]\\/?.,;:|\\)*~`!^\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"\\'\\·]',\n",
    "#                           ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text) # 여러개의 공백을 하나의 공백으로 치환\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "text = [clean_text(x) for x in comments] # 한글외 모든 문자 제거\n",
    "text = [x.strip() for x in text] # 문자열 양 끝에 있는 공백과 \\n 기호 삭제 \n",
    "text = [n for n in text if len(n) >=10] # 글자 수 가 10이상인 댓글만 사용\n",
    "text = pd.DataFrame(text, columns=['cmt']) # dataframe 형식으로 변환\n",
    "print(len(text))\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cmt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[연대, 법대, 출신, 토익, 취업, 건, 대, 충주, 스펙, 귀걸이, 증명, 사진...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[전직, 공안, 검사, 출신, 이자, 일도, 만들고, 말도, 만들고, 그렇게, 일반...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[교활이, 이새, 키, 호, 뇨, 밑, 있을때, 다, 벙어리, 인줄, 근데, 보니,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[이렇게, 입, 작자, 어찌, 대권, 건지, 한심, 하지, 짝, 누리, 당]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[연세대, 아들, 간, 뭐, 대수, 라고, 귀걸이, 아빠, 조사, 해봐라, 정권]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 cmt\n",
       "0  [연대, 법대, 출신, 토익, 취업, 건, 대, 충주, 스펙, 귀걸이, 증명, 사진...\n",
       "1  [전직, 공안, 검사, 출신, 이자, 일도, 만들고, 말도, 만들고, 그렇게, 일반...\n",
       "2  [교활이, 이새, 키, 호, 뇨, 밑, 있을때, 다, 벙어리, 인줄, 근데, 보니,...\n",
       "3         [이렇게, 입, 작자, 어찌, 대권, 건지, 한심, 하지, 짝, 누리, 당]\n",
       "4      [연세대, 아들, 간, 뭐, 대수, 라고, 귀걸이, 아빠, 조사, 해봐라, 정권]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "dicpath = 'user_dict.txt' \n",
    "komoran = Komoran(userdic=dicpath) # 사용자 사전 등록\n",
    "\n",
    "stopwords = pd.read_excel('stopwords100.xlsx', encoding='utf-8') # 불용어 사전 로드\n",
    "stopwords = set(list(stopwords['Column1']))\n",
    "\n",
    "text['cmt'] = text.apply(lambda row: komoran.nouns(row['cmt']), axis=1) # Komoran 형태소 분석기에서 명사로 인식되는 단어만 사용\n",
    "text['cmt'] = text['cmt'].apply(lambda x: [word for word in x if word not in stopwords]) # 불용어 제거\n",
    "text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [연대, 법대, 출신, 토익, 취업, 충주, 스펙, 귀걸이, 증명, 사진, 이력서,...\n",
       "1    [전직, 공안, 검사, 출신, 이자, 일도, 만들고, 말도, 만들고, 그렇게, 일반...\n",
       "2    [교활이, 이새, 있을때, 벙어리, 인줄, 근데, 보니, 완전, ㅎㅎ, 두드러기, ...\n",
       "3                    [이렇게, 작자, 어찌, 대권, 건지, 한심, 하지, 누리]\n",
       "4              [연세대, 아들, 대수, 라고, 귀걸이, 아빠, 조사, 해봐라, 정권]\n",
       "Name: cmt, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_doc = text['cmt'].apply(lambda x: [word for word in x if len(word) >1]) # 한 글자인 단어 제거\n",
    "tokenized_doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(tokenized_doc, size=150, window=5, min_count=5, workers=4, sg=1) # 댓글의 명사를 벡터로 분산표현\n",
    "# note that these are not the best parameters. you should try something else to get better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('니들', 0.9731961488723755),\n",
       " ('친일', 0.9670661091804504),\n",
       " ('자유한국당', 0.964316725730896),\n",
       " ('친일파', 0.9640794992446899),\n",
       " ('자유당', 0.9603596329689026),\n",
       " ('수구', 0.9578806757926941),\n",
       " ('보수', 0.9556160569190979),\n",
       " ('매국노', 0.9535486102104187),\n",
       " ('니네', 0.9524215459823608),\n",
       " ('애국', 0.9471304416656494)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"자한당\") # 입력한 단어와 가장 가까운 10개 단어 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'naver_01.sav' \n",
    "pickle.dump(model, open(filename, 'wb')) # 학습한 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('친일파', 0.9788994193077087),\n",
       " ('자유당', 0.9688515663146973),\n",
       " ('친일', 0.9686806201934814),\n",
       " ('자유한국당', 0.9677141904830933),\n",
       " ('니들', 0.9562883377075195),\n",
       " ('애국', 0.9520573616027832),\n",
       " ('매국노', 0.9463508725166321),\n",
       " ('극우', 0.944614589214325),\n",
       " ('세력', 0.9406320452690125),\n",
       " ('니네', 0.940369725227356)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb')) # 저장한 모델 재사용\n",
    "loaded_model.wv.most_similar(\"자한당\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
